{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from TextRank import TextRank\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created urls_and_sentences.csv\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(project_folder + 'done_links.txt'):\n",
    "    pass\n",
    "else:\n",
    "    done_links_file = open(project_folder + 'done_links.txt', 'w')\n",
    "    done_links_file.close()\n",
    "    print('Created done_links.txt')\n",
    "if os.path.exists(project_folder + 'urls_and_sentences.csv'):\n",
    "    pass\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['url', 'sentence'])\n",
    "    df.to_csv(project_folder + 'urls_and_sentences.csv', index=False)\n",
    "    print('Created urls_and_sentences.csv')\n",
    "done_links_path = project_folder + 'done_links.txt'\n",
    "urls_and_sentences_path = project_folder + 'urls_and_sentences.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Raw_Text(object):\n",
    "    '''\n",
    "    The class that will be used to perform all operations on the downloaded texts.\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def _read_file(file_name):\n",
    "        '''\n",
    "        :param: given filename after raw_data_path to be read.\n",
    "        Returns the url and the text that it found in the given file\n",
    "        '''\n",
    "        file_to_read = open(raw_data_path + file_name, 'r')\n",
    "        raw_text = file_to_read.read()\n",
    "        file_to_read.close()\n",
    "        url = raw_text.split('\\n')[0]\n",
    "        text = str(raw_text.split('\\n')[1:])\n",
    "        return([url, text])\n",
    "    @staticmethod\n",
    "    def _get_text(cls, file_name):\n",
    "        '''\n",
    "        Just returns the text.        \n",
    "        :param: given filename from which text will be extracted.\n",
    "        '''\n",
    "        text = cls._read_file(file_name)[1]\n",
    "        return(text)\n",
    "    @staticmethod\n",
    "    def _get_url(cls, file_name):\n",
    "        '''\n",
    "        Just returns url.\n",
    "        '''\n",
    "        url = cls._read_file(file_name)[0]\n",
    "        return(url)\n",
    "    @classmethod\n",
    "    def print_text(cls, file_name):\n",
    "        '''\n",
    "        Uses read_file to print the text body of the input.\n",
    "        :param: given filename after raw_data_path to be printed.\n",
    "        '''\n",
    "        text = cls._get_text(cls, file_name)\n",
    "        print(text)\n",
    "    @classmethod\n",
    "    def print_url(cls, file_name):\n",
    "        '''\n",
    "        Uses read_file to print the url of the input.\n",
    "        :param: given filename from which url will be extracted.\n",
    "        '''\n",
    "        url = cls._get_url(cls, file_name)\n",
    "        print(url)\n",
    "        \n",
    "    @staticmethod\n",
    "    def text_rank_sentences(cls, file_name, no_jobs=5):\n",
    "        '''\n",
    "        Uses Text_Rank.py to return the most important sentences.\n",
    "        :param: given filename after raw_data_path to be read.\n",
    "        :param no_jobs:  How many sentences to be returned (AS A LIST)\n",
    "        '''\n",
    "        text = cls._get_text(cls, file_name)\n",
    "        sentences_list = TextRank.fit(text, n_jobs=no_jobs)\n",
    "        return sentences_list\n",
    "    @classmethod\n",
    "    def print_ranked_sentences(cls, file_name):\n",
    "        sentences_list = cls.text_rank_sentences(cls, file_name)\n",
    "        for idsent, sentence in enumerate(sentences_list):\n",
    "            sentence = sentence.replace(u'\\xa0', u' ')\n",
    "            print('{}:  {}'.format(idsent + 1, sentence))\n",
    "    @classmethod\n",
    "    def get_sentences_with_numbers(cls, file_name):\n",
    "        '''\n",
    "        Returns sentences that have numbers in it. \n",
    "        '''\n",
    "        text = cls._get_text(cls, file_name)\n",
    "        sentences_with_numbers = []\n",
    "        for sent in nltk.sent_tokenize(text):\n",
    "                if bool(re.search(r'\\d', sent)):\n",
    "                    sent = sent.replace(u'\\xa0', u' ')\n",
    "                    sentences_with_numbers.append(sent)\n",
    "\n",
    "        return sentences_with_numbers\n",
    "    @classmethod\n",
    "    def get_number_and_keyword_sentences(cls, file_name, keyword_list_1, keyword_list_2 = None):\n",
    "        \n",
    "        print(file_name)\n",
    "        \n",
    "        '''\n",
    "        Returns all sentences that have numbers in them AND include some specified keywords.\n",
    "        :param keyword_list_1:  The ultimate keyword list.\n",
    "        :param keyword_list_2:  The topic-specific keyword list.\n",
    "        '''\n",
    "        number_sentences = cls.get_sentences_with_numbers(file_name)\n",
    "        return_list = []\n",
    "        for sentence in number_sentences:\n",
    "            if any(word in sentence.lower() for word in keyword_list_1):\n",
    "                return_list.append(sentence)\n",
    "            else:\n",
    "                pass\n",
    "        return return_list\n",
    "    @staticmethod\n",
    "    def loop_through_sentences(cls, sentences_list, url, file_name):\n",
    "        '''\n",
    "        The interface shown for each sentence\n",
    "        '''\n",
    "        help_string = '''\n",
    "        This is the help message.\n",
    "        Press 'y' to add sentence to the saved sentences.\n",
    "        Press 'n' to go to next sentence\n",
    "        Press 'h' for help message\n",
    "        Press 'q' to quit()\n",
    "        '''\n",
    "        yes_sentences = []\n",
    "        for sentence in sentences_list:\n",
    "            if sentence not in list(pd.read_csv(project_folder + 'urls_and_sentences.csv')['sentence']):\n",
    "                print(sentence)\n",
    "                answer = input('y, n, h, q: ')\n",
    "                if answer == 'y':\n",
    "                    yes_sentences.append(sentence)\n",
    "                    try:\n",
    "                        df = pd.read_csv(project_folder + 'urls_and_sentences.csv')\n",
    "                    except:\n",
    "                        df = pd.DataFrame(columns=['url', 'sentence'])\n",
    "                    df.loc[len(df)] = [url, sentence]\n",
    "\n",
    "                    df.to_csv(project_folder + 'urls_and_sentences.csv', index=False)\n",
    "                    print('Sentence added')\n",
    "                elif answer == 'n':\n",
    "                    pass\n",
    "                elif answer == 'h':\n",
    "                    print(help_string)\n",
    "                elif answer == 'q':\n",
    "                    print('quitting')\n",
    "                    quit()\n",
    "            else:\n",
    "                pass\n",
    "        done_file = open(project_folder + 'done_links.txt', 'a')\n",
    "        done_file.write('{}\\n'.format(url))\n",
    "        print('You are done with {}'.format(file_name))\n",
    "        \n",
    "    @classmethod\n",
    "    def interface(cls, file_name, numbered_senteces = True, text_ranked = True, numbered_and_keywords = False):\n",
    "        '''\n",
    "        Takes the file and shows the user one by one, to decide if they are important\n",
    "        '''\n",
    "        \n",
    "        ultimate_keyword_list = ['thousand', 'thousands', 'hundred', 'hundreds', 'millions', 'million', 'euro ', 'dollar', 'user', 'users', 'tonnes', 'tonne', 'liter', 'litre', 'liters', 'downloads', 'likes', 'eur', 'usd'\n",
    "        ]\n",
    "        \n",
    "        #Appending all sentences to snetences_list\n",
    "        sentences_list = []\n",
    "        #All sentences from the Text_Rank\n",
    "        if text_ranked == True:\n",
    "            for sentence in cls.text_rank_sentences(cls, file_name):\n",
    "                sentences_list.append(sentence)\n",
    "        else:\n",
    "            pass\n",
    "        #All sentences that have some numbers in them\n",
    "        if numbered_senteces == True:\n",
    "            for sentence in cls.get_sentences_with_numbers(cls, file_name):\n",
    "                sentences_list.append(sentence)\n",
    "        else:\n",
    "            pass\n",
    "        #\n",
    "        if numbered_and_keywords == True:\n",
    "            print(cls, file_name,  ultimate_keyword_list,  None)\n",
    "            for sentence in cls.get_number_and_keyword_sentences(file_name = file_name, keyword_list_1= ultimate_keyword_list , keyword_list_2 = None):\n",
    "                sentences_list.append(sentence)\n",
    "        print('There are {} sentences'.format(len(sentences_list)))\n",
    "        url = cls._get_url(cls, file_name)\n",
    "        done_list_file = open(project_folder + 'done_links.txt', 'r')\n",
    "        done_url_list = done_list_file.read().split('\\n')\n",
    "        done_list_file.close()\n",
    "        if url not in done_url_list:\n",
    "            if os.path.exists(processed_data_path + file_name):\n",
    "                print('This file has already been processed.')\n",
    "            answer = None\n",
    "            while answer not in ['Start', 'quit']:\n",
    "                answer = input('What now? ')\n",
    "                if answer == 'Start':\n",
    "                    cls.loop_through_sentences(cls, sentences_list, url, file_name)\n",
    "                elif answer == 'quit':\n",
    "                    quit()\n",
    "                else:\n",
    "                    print('\\'Start\\' to start processing or \\'quit\\' for quitting: ')\n",
    "        else:\n",
    "            print('Seems like this page has been processed before.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Raw_Text'> 1.txt ['thousand', 'thousands', 'hundred', 'hundreds', 'millions', 'million', 'euro ', 'dollar', 'user', 'users', 'tonnes', 'tonne', 'liter', 'litre', 'liters', 'downloads', 'likes', 'eur', 'usd'] None\n",
      "1.txt\n",
      "There are 12 sentences\n",
      "Seems like this page has been processed before.\n"
     ]
    }
   ],
   "source": [
    "Raw_Text.interface(file_name='1.txt', numbered_senteces=False, text_ranked=False, numbered_and_keywords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Asking for project name, and creating folders:\n",
    "project folder\n",
    "'''\n",
    "project_name = input('Project name:')\n",
    "output_path = os.path.join(os.path.dirname('__file__'), '..', ) + '/output/'\n",
    "try:\n",
    "    project_folder = os.path.join(os.path.dirname('__file__'), '..', ) + '/output/{}/'.format(project_name)\n",
    "except:\n",
    "    quit('Please Run Text_downloader.py first')\n",
    "    '''    \n",
    "except:\n",
    "    os.makedirs(output_path + '/{}/'.format(project_name))\n",
    "    project_folder = os.path.join(os.path.dirname('__file__'), '..', ) + '/output/{}/'.format(project_name)\n",
    "'''\n",
    "if os.path.exists(project_folder + '/raw_data/'):\n",
    "    raw_data_path = project_folder + '/raw_data/'\n",
    "else:\n",
    "    print('raw_data folder does not exist, run Text_downloader.py, to create one!' )\n",
    "if os.path.exists(project_folder + '/processed_data/'):\n",
    "    pass\n",
    "else: \n",
    "    os.makedirs(project_folder + '/processed_data/')\n",
    "processed_data_path = project_folder + '/processed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checking if service files exist.\n",
    "'''\n",
    "if os.path.exists(project_folder + 'done_links.txt'):\n",
    "    pass\n",
    "else:\n",
    "    done_links_file = open(project_folder + 'done_links.txt', 'w')\n",
    "    done_links_file.close()\n",
    "    print('Created done_links.txt')\n",
    "if os.path.exists(project_folder + 'urls_and_sentences.csv'):\n",
    "    pass\n",
    "else:\n",
    "    df = pd.DataFrame(columns=['url', 'sentence'])\n",
    "    df.to_csv(project_folder + 'urls_and_sentences.csv', index=False)\n",
    "    print('Created urls_and_sentences.csv')\n",
    "done_links_path = project_folder + 'done_links.txt'\n",
    "urls_and_sentences_path = project_folder + 'urls_and_sentences.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number which txt you want to process: 2\n",
      "Do you want to use numbered sentences? n\n",
      "Do you want to use text_ranked sentences? n\n",
      "Do you want to search for sentences with numbers AND keywords?y\n",
      "<class '__main__.Raw_Text'> 2.txt ['thousand', 'thousands', 'hundred', 'hundreds', 'millions', 'million', 'euro ', 'dollar', 'user', 'users', 'tonnes', 'tonne', 'liter', 'litre', 'liters', 'downloads', 'likes', 'eur', 'usd'] None\n",
      "2.txt\n",
      "There are 42 sentences\n",
      "What now? s\n",
      "'Start' to start processing or 'quit' for quitting: \n",
      "What now? d\n",
      "'Start' to start processing or 'quit' for quitting: \n",
      "What now? Start\n",
      "['', '', '', '', '', '                                                                Error: ', '1 How crisis-resistant and competitive are Europe s Eco- Industries?\n",
      "y, n, h, q: n\n",
      "Founded in 1995, the Ecologic Institute is a partner in the network of Institutes for European Environmental Policy.\n",
      "y, n, h, q: n\n",
      "The Ecologic Institute acts in the public interest; donations are tax-deductible.3 Table of Contents Main findings of the study Introduction Data source Development of Eco-Industries Turnover and growth of Eco-Industries Competitiveness and Resilience of Eco-Industries Innovation in the Eco-Industries Patenting activity in environmental industries Patenting activity in environmental industries across countries Patenting activity for selected environment-related technologies Patenting activity in Europe compared to the US and China Public funding for environmental research Country Briefs European countries Germany Italy Poland Portugal UK Non-European countries China Mexico US Conclusions and recommendations References i4 List of Tables Table 1: Growth rates and shares of different LCEGS sub-sectors... 9 Table 2: Growth rates in LCEGS and GDP for eight countries, Source: Eurostat and IMF Table 3: Shares and growth rates of patent applications for environment-related technologies, EU, China and USA Table 4: Share of environmental research in state expenditure for civil R&D, Table 5: All private investment vs. investment in renewables in Germany, Table 6: Nominal growth rates in LCEGS and GDP for Italy, Table 7: Nominal growth rates in LCEGS and GDP for Poland, Table 8: GDP growth and renewable share in Portugal, Table 9: Nominal growth rates in LCEGS and GDP for Portugal, Table 10: Development of sub-sectors in the UK Table 11: Nominal growth rates in LCEGS and GDP for the UK, Table 12: Nominal growth rates in LCEGS and GDP for China, Table 13: Nominal growth rates in LCEGS and GDP for Mexico, Table 14: Nominal growth rates in LCEGS and GDP for US, List of Figures Figure 1: Size of the LCEGS sector (in % of GDP) and annual growth, Figure 2: Number of patent applications for environment-related technologies in eight selected countries, Source: OECD ENV-Tech Indicator Set Figure 3: Patent applications for selected environment-related technologies in the EU-28, Source: OECD ENV-Tech Indicator Set Figure 4: Patenting activity for selected technologies in the EU-28, (2000 = 100).\n",
      "y, n, h, q: n\n",
      "The global market share (22%) of European Eco-Industries was stable over this period, despite the fact that overall economic growth in Europe was much weaker than the world average during this period.\n",
      "y, n, h, q: y\n",
      "Sentence added\n",
      "In four of the five European countries considered in this study, Eco-Industries have grown faster than GDP between 2008 and In Italy and Portugal, where nominal GDP has stagnated during this period, Eco-Industries have grown by 9.4 and 5%, respectively, from 2008 to But also in Germany, whose economy remained relatively robust during the crisis, Eco-Industries were a driver of growth, with an increase of 13% between 2008 and There are inherent reasons why Eco-Industries have outperformed the rest of the economy, particularly during the economic crisis.\n",
      "y, n, h, q: y\n",
      "Sentence added\n",
      "38 1 Introduction According to OECD and Eurostat, Eco-Industries are activities which produce goods and services to measure, prevent, limit, minimise or correct environmental damage to water, air and soil, as well as problems related to waste, noise and eco-systems.\n",
      "y, n, h, q: q\n",
      "quitting\n",
      "A 2009 study on Eco-Industries is highlighted by the European Commission on its website: \"in 2008, the EU eco-industry provided 4 million jobs.\n",
      "y, n, h, q: q\n",
      "quitting\n",
      "With a turnover of 300 billion and a growth rate of 8% a year, eco-industries are a key contributor to the Europe 2020 strategy for smart, sustainable and inclusive growth.\n",
      "y, n, h, q: q\n",
      "quitting\n",
      "49 The contents of the report are divided as follows: Chapter 2 describes the data source of the report; Chapter 3 summarizes the development of Eco-Industries in Europe and the world; Chapter 4 provides an overview on innovation in Eco-Industries; and Chapter 5 summarises and highlights the development of Eco-Industries in the eight sample countries.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p36/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p36/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p36/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-37a91cf9f28e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdo_num_and_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mRaw_Text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbered_senteces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_numbered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_ranked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_text_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbered_and_keywords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_num_and_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-c43474af98e6>\u001b[0m in \u001b[0;36minterface\u001b[0;34m(cls, file_name, numbered_senteces, text_ranked, numbered_and_keywords)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What now? '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Start'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop_through_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-c43474af98e6>\u001b[0m in \u001b[0;36mloop_through_sentences\u001b[0;34m(cls, sentences_list, url, file_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'urls_and_sentences.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y, n, h, q: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0myes_sentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_file_name = input('Enter the number which txt you want to process: ') + '.txt'\n",
    "do_numbered = input('Do you want to use numbered sentences? ')\n",
    "if do_numbered == 'y':\n",
    "    do_numbered = True\n",
    "else:\n",
    "    do_numbered = False\n",
    "do_text_rank = input('Do you want to use text_ranked sentences? ')\n",
    "if do_text_rank == 'y':\n",
    "    do_text_rank = True\n",
    "else:\n",
    "    do_text_rank = False\n",
    "do_num_and_key = input('Do you want to search for sentences with numbers AND keywords?' )\n",
    "if do_num_and_key == 'y':\n",
    "    do_num_and_key = True\n",
    "else:\n",
    "    do_num_and_key = False\n",
    "Raw_Text.interface(file_name=input_file_name, numbered_senteces=do_numbered, text_ranked=do_text_rank, numbered_and_keywords=do_num_and_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
