{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrusolomes/miniconda3/envs/p36/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/alexandrusolomes/miniconda3/envs/p36/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens: \n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"This is your first text book\", \"This is the third text for analysis\", \"This is another text\"]\n",
    "# word tokenize and stem\n",
    "text = [\" \".join(tokenize(txt.lower())) for txt in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thi is your first text book',\n",
       " 'thi is the third text for analysi',\n",
       " 'thi is anoth text']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrusolomes/miniconda3/envs/p36/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1039: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(text).todense()\n",
    "# transform the matrix to a pandas df\n",
    "matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names())\n",
    "# sum over each document (axis=0)\n",
    "top_words = matrix.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thi        0.969378\n",
       "text       0.969378\n",
       "is         0.969378\n",
       "anoth      0.699030\n",
       "your       0.497120\n",
       "first      0.497120\n",
       "book       0.497120\n",
       "third      0.445149\n",
       "the        0.445149\n",
       "for        0.445149\n",
       "analysi    0.445149\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysi</th>\n",
       "      <th>anoth</th>\n",
       "      <th>book</th>\n",
       "      <th>first</th>\n",
       "      <th>for</th>\n",
       "      <th>is</th>\n",
       "      <th>text</th>\n",
       "      <th>the</th>\n",
       "      <th>thi</th>\n",
       "      <th>third</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.49712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.445149</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.445149</td>\n",
       "      <td>0.262912</td>\n",
       "      <td>0.262912</td>\n",
       "      <td>0.445149</td>\n",
       "      <td>0.262912</td>\n",
       "      <td>0.445149</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.69903</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    analysi    anoth     book    first       for        is      text  \\\n",
       "0  0.000000  0.00000  0.49712  0.49712  0.000000  0.293607  0.293607   \n",
       "1  0.445149  0.00000  0.00000  0.00000  0.445149  0.262912  0.262912   \n",
       "2  0.000000  0.69903  0.00000  0.00000  0.000000  0.412859  0.412859   \n",
       "\n",
       "        the       thi     third     your  \n",
       "0  0.000000  0.293607  0.000000  0.49712  \n",
       "1  0.445149  0.262912  0.445149  0.00000  \n",
       "2  0.000000  0.412859  0.000000  0.00000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
